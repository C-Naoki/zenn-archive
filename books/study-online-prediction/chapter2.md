---
title: "第２章: オンライン凸最適化"
---
# Chapter 2 オンライン凸最適化

オンライン凸最適化 (online convex optimization) とは様々なオンライン予測問題を抽象化し、統一的に扱うための問題の枠組み

- 余談だが、非凸最適化に関する研究にも取り組まれている [[Hazan et al., 2017]](https://proceedings.mlr.press/v70/hazan17a/hazan17a.pdf)

## 2.1 オンライン凸最適化の枠組み

オンライン凸最適化は事例空間と呼ばれる凸集合 $\mathcal{X}$ と $\mathcal{X}$ 上の凸関数の集合 $\mathcal{F}\subset\{f:\mathcal{X}\to\R\mid f\>\!\text{ is convex}\}$ の組 $(\mathcal{X, F})$ によって定義される

- プレイヤーと敵対者との間の関係は以下の３つのステップで構成される

    各試行 $t=1, \ldots, T$ において

    1. プレイヤーは点 $\bm{x}_t\in\mathcal{X}$ を選ぶ
        - 選ぶとか言ってるけど、$t-1$ 番目までの試行で得られたデータを用いて予測すると言っても差し支え無さそう
    2. 敵対者は凸関数 $f_t\in\mathcal{F}$ を選び、プレイヤーに与える
    3. プレイヤーは損失 $f_t(\bm{x}_t)$ を被る
- このプロトコルを考えるとわかるように、プレイヤーは関数 $f_t$ を明示的に受け取ると仮定する
    - ゆえに、任意の点における勾配やヘシアンなども計算可能
    - このような仮定は**完全情報設定** (full information setting) と呼ばれている
    - 一方で関数値 $f_t(\bm{x}_t)$ のみが与えられる状況を**バンディット設定** (bandit setting) と呼ばれる
    - 🧐「$f_t$ が与えられる」という状況を言い換えると、固定の損失関数 $f$ と $t$ 番目の試行の正解 $y_t$ が与えられると言っても良さそう？
    - この損失関数の構造に応じて、解くべき課題の種類が変わったりなどする
        - e.g., 二乗損失、分類損失、ロジスティック損失等
    - また $\bm{x}_t$ の選び方がいわゆるどのようなモデルを用いるか？という議題に相当する
        - e.g., 線形回帰 $x_t=\bm{w}^\top\bm{z}_t$
            - $\bm{z}_t$ は事例とも呼ばれ、入力データとして逐次的に得られる
            - 凸関数 $f_t$ はモデルパラメータ $\bm{w}$ に対する関数としてみられるようになった
        - このように関数の入力が「予測値」になったり「モデルパラメータ」になったりする、ここら辺は問題に合わせてよしなに変えても良い？

このような問題設定を踏まえて、プレイヤーの目標はリグレットを最小化することである

**Definition 2.1**
オンライン凸最適化問題 $(\mathcal{X, F})$ に対し、プレイヤーの用いる乱択アルゴリズム $A$ とする。また、敵対者の生成する凸関数の系列を $S=(f_1, \ldots, f_T)$、$A$ の選んだ点の系列を $\bm{x}_1, \ldots, \bm{x}_T$ とする。この時、アルゴリズム $A$ の関数列 $S$ に対するリグレットを

$$
\text{Regret}_A(S)=\mathbb{E}\left[\sum_{t=1}^Tf_t(\bm{x}_t)\right]-\min_{\bm{x}\in\mathcal{X}}\sum_{t=1}^Tf_t(\bm{x})
$$

また、総試行回数 $T$
    に対するリグレットを

$$
\text{Regret}_A(T)=\min_{S\in\mathcal{F}}\text{Regret}_A(S)
$$

と定義する

- 上記の定義において、各 $t$ 番目の試行に対する最小値を選ぶと、相対損失が $\Omega(T)$ となってしまい、これはプレイヤーがランダムな選択をしても結果が変わらず、自明な結果しか得られない。
- 📒 本編のオンライン線形回帰問題の例を交えるとわかりやすい
    - 各サンプルデータに対して損失最小の線を合計 $T$ 個選んでしまうと、もはやそれは学習なのか？みたいな状況になる
    - もし定義2.1のような固定点の場合で考えると、第２項目の誤差はバッチ処理をした時の誤差と一致するようになり、それだと比較として妥当性のあるものになる

## 2.2 Follow The Leader (FTL) 戦略

プレイヤーの最もシンプルな戦略は、$t$ 番目の試行において、過去に受け取った凸関数の和 $f_1+\cdots+f_{t-1}$ を最小化するような固定点 $\bm{x}$ を予測すること

- この戦略は **Follow The Leader (FTL) 戦略**と呼ばれている
- 数式化するとこの戦略では以下のような問題を解くことに相当する

    $$
    \bm{x}_t=\argmin_{\bm{x}\in\mathcal{X}}\sum_{\tau=1}^{\tau-1}f_\tau(\bm{x})
    $$

    - 非常にシンプルながらも一定問題に対して有効であるが、シンプルさ故の限界も知られている

### 2.2.1 FTL戦略の有効性

FTL戦略を用いたリグレット解析を行うにあたって、最も基本的な補題である **Be-The-Leader (BTL) 補題**を簡単に説明する

**Lemma 2.1**
任意の点 $\bm{u}\in\mathcal{X}$ に対して

$$
\sum_{t=1}^Tf_{t}(\bm{x}_{t+1})\leq\sum_{t=1}^Tf_{t}(\bm{u})
$$

が成立する、ただし $\bm{x}_{t+1}=\argmin_{\bm{x}\in\mathcal{X}}\sum_{\tau=1}^tf_\tau(\bm{x})$ を満たす

- 本来は $f_t$ を知る前に $\bm{x}$ の選択を行っておく必要があるが、上記の $\bm{x}_{t+1}$ というのは $f_t$ を知った後にそれに基づいて $\bm{x}$ を決定したという夢想戦略を意味する
- この補題は、任意の固定ベクトルに対して、夢想戦略を用いて推定した結果以上に精度の良い推定は実現できない、ということを意味している

上記の式の両辺を $\sum_{t=1}^T f_t(\bm{x}_t)$ で引いたことによって FTL 戦略のリグレットのバウンドが導出される

- これは **FTL-BTL 補題**とも呼ばれる
- このバウンドは「FTL戦略の性能の悪さは、その戦略の不安定さによって決まる」という状態を数式化したもの
    - その戦略の不安定さ：$t$ 番目の試行と $t+1$ 番目の試行の損失がなだらかに変化するのであれば、その分リグレットも小さくできる

### 2.2.2 FTL戦略の限界

最後の FTL-BTL 補題によって以下のような限界点が導かれる

> $f_t(\bm{x}_t)$ に対して $f_t(\bm{x}_{t+1})$ が極端に大きくなる、すなわち戦略が不安定であるとき、リグレットは非常に大きくなってしまう
>
- これは特に、線形の損失関数である場合に不安定な戦略となってしまう
- 📒 この限界点を直感的に理解できるような有名な例が存在する
    - 事例空間 $\mathcal{X}=[-1, 1]$、凸関数 $f_t(x)=ax$ であるような状態を考える
    - 結論としては、意地悪な敵対者の戦略を構築した場合、リグレットが $O(T)$ となってしまう

## 2.3 Follow The Regularized Leader (FTRL) 戦略

FTL戦略の弱点を補うような新たな戦略の代表的な方法の１つとして「正則化」を活用したものがある

- 正則化の導入によって、過去の経験的な損失にとらわれずに、今後現れるであろう将来の損失に対して備えると見ることもできる
- 数式化するとこの戦略では以下のような問題を解くことに相当する

    $$
    \bm{x}_t=\argmin_{\bm{x}\in\mathcal{X}}\sum_{\tau=1}^{\tau-1}f_\tau(\bm{x})+R(\bm{x})
    $$

    - $R(\bm{x}):\mathcal{X}\to\R$ は狭義凸な関数である
    - FTLR 戦略は FTL 戦略と比べて頑健であるだけでなく、従来の様々なオンライン予測手法に対して統一的な特徴づけを与える

### 2.3.1 損失関数が線形の場合

### 2.3.2 オンライン線形最適化問題への帰着

### 2.3.2 オンライン勾配降下法