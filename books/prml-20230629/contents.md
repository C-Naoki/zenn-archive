---
title: "全体像"
---
# 全体像
各章に関するあらましを以下の表にまとめました。

|  タイトル  | あらまし |
|:---:|:---:|
| **第１章: 序論** |  |
| 1.1: 多項式曲線フィッティング | 多項式を用いたデータへのフィッティングを考える |
| 1.2: 確率論 | 不確実性に関する定量化と操作に関して一貫した枠組みを与える |
| 1.2.1:  確率密度 | 離散的な事象集合に定義される確率分布のように<br>連続変数に対しても同様に確率というものを考えたい |
| 1.2.2: 期待値と分散 | 確率を含む最も重要な操作の内１つである関数の重み付き平均について |
| 1.2.3: ベイズ確率 | ベイズ的考え方を用いることで不確実性を定量化したい |
| 1.2.4: ガウス分布 | 様々な確率分布の中で最も重要なガウス分布を導入する |
| 1.2.5: 曲線フィッティング再訪 | i) 誤差関数及び正則化に関する洞察を得る, ii)完全なベイズ的取り扱いを知る, という目的を達成するために多項式曲線フィッティングを眺め直す |
| 1.2.6: ベイズ曲線フィッティング | 完全なベイズアプローチを考える |
| 1.3: モデル選択 | 実際に応用する際に決定する必要がある<br>モデルの複雑さを支配するパラメータについて |
| 1.4: 次元の呪い | パターン認識テクニックの設計に重要な影響を与える要因である<br>高次元空間の取り扱いについて |
| 1.5: 決定理論 | パターン認識で遭遇する不確かさを含む状況における<br>最適な意思決定を行う事を可能にしたい |
| 1.5.1: 誤識別率の最小化 | 誤識別をできるだけ少なくしたいということだけを目標としている |
| 1.5.2: 期待損失の最小化 | 単に誤識別を減らすよりも複雑化した決定理論について |
| 1.5.3: 棄却オプション | クラス分類が難しい場合は全て機械に選択を委ねる必要はない |
| 1.5.4: 推論と決定 | 決定問題を解く時に考えられる３種類のアプローチについて |
| 1.5.5: 回帰のための損失関数 | クラス分類だけでなく回帰でも決定問題を取り扱いたい |
| 1.6: 情報理論 | パターン認識や機械学習テクニックの発展にも有用である<br>情報理論に関する概念を導入する |
| 1.6.1: 相対エントロピーと相互情報量 | 未知の分布$p(\bm{x})$を近似的に$q(\bm{x})$でモデルする事を考える |
| **第２章: 確率分布** |  |
| 2.1: 二値変数 | コイン投げのような二値確率変数 $x = \{0, 1\}$ の場合を考える |
| 2.1.1: ベータ分布  | 二項分布のパラメータをベイズ主義的に推定する |
| 2.2: 多値変数 | 相互に排他的な$K$個の可能な状態のうち一つを取るような<br>離散変数を取り扱う |
| 2.2.1: ディリクレ分布 | 多項分布のパラメータをベイズ主義的に推定する |
| 2.3: ガウス分布 | 様々な場面で現れ、利用価値も様々なガウス分布を紹介 |
| 2.3.1: 条件付きガウス分布 | 多変量ガウス分布の重要な特性について考察する |
| 2.3.2: 周辺ガウス分布 | 周辺ガウス分布について考える |
| 2.3.3: ガウス変数に対するベイズの定理 | 以後の章で頻繁に現れる以下のような問題に対する<br>一般的な結果を算出しておく |
| 2.3.4: ガウス分布の最尤推定 | 多変量ガウス分布から観測値$\{x_n\}$が独立に得られたと仮定したデータ集合に対して、分布のパラメータを最尤推定法で推定する |
| 2.3.5: 逐次推定 | データ点を１度に１つずつ処理してそれを破棄することを考える |
| 2.3.6: ガウス分布に対するベイズ推論 | パラメータ上の事前分布を導入して、ベイズ主義的な扱い方を導く |

# 記号の説明
🧐: 僕が勉強する過程で理解するために自分なりに噛み砕いた表現や、疑問に思ったことを記載しています。(誤った内容がございましたら、ご指摘いただけると大変助かります🙇‍♂️)

# 更新情報
2023/6/30: 第１章追加
