---
title: "第１章: 序論"
---
# 第１章: 序論
様々なタスクに対して、共通である柱となる基本的な考え方を簡単な例を用いて説明する

- 学習は主に以下の3種類に大別される
    - **教師あり学習**
        - 訓練データが、入力ベクトルとそれに対応する目標ベクトルで構成される課題のこと
        - 主な課題として、各入力ベクトルを有数の離散カテゴリの１つに割り当てる**クラス分類**と、求める出力が連続変数であるような**回帰**が存在する
    - **教師なし学習**
        - 訓練データが入力ベクトルのみで構成されており、対応する目標ベクトルが存在しない課題のこと
        - 類似したグループを見つける**クラスタリング**や、データの分布を求める**密度推定**、または、高次元データを2, 3次元データに射影する**視覚化**といった課題が存在する
    - **強化学習**
        - 報酬を最大化する適当な行動を試行錯誤で見つけるための課題
        - 行動は主に、新しい種類の行動がどの程度有効であるかを試す**探査**、高い報酬が得られることがわかっている**利用**に分かれる

## 1.1: 多項式曲線フィッティング

多項式を用いたデータへのフィッティングを考える

$$
y(x, \bm{w}) = \sum_{j=0}^Mw_jx^j
$$

- 最適な多項式を求めるためには、任意の$\mathbf{w}$について、$y(x, \bm{w})$ の値と訓練集合のデータ点とのズレを測る**誤差関数**(error function)の最小化で達成できる
    - よく用いられているものは**二乗和誤差**(SSE)
- 最適な$M$を求める問題に関しては、**モデル比較**(model comparision) or **モデル選択**(model selection) と呼ばれる重要な概念
    - $M$ が大きすぎると汎化性がなくなる → **過学習**(over-fitting)
- 過学習の問題を避ける方法の一つに、**正則化項**(regulization)の追加がある
    - 具体的には、**罰則項**(penalty)を誤差関数に加える
        - 2次の罰則項は特別に**リッジ回帰**(ridge regression)と呼ばれている
    - 推定パラメータを特定の値に近づける手法を統計学の分野で**縮小推定**(shrinkage)と呼ぶ
        - 正則化項の場合は”係数”を”0”に近づける
    - ニューラルネットワークの文脈では**荷重減衰**(weight decay)と呼ばれている
        - i.e. 重みが大きくなりすぎないように制御を加えること
- モデルの複雑さを最適化するために、**確認用集合**(validation set)に分けることがある
    - 別名: **ホールドアウト集合**(hold-out set)
    - 但し、貴重な訓練データの一部を用いるので好ましくない

## 1.2: 確率論

**確率論**(probability theory)とは、不確実性に関する定量化と操作に関して一貫した枠組みを与える

- パターン認識の分野における鍵となる概念は**不確実性**
    - 計測ノイズ及びデータサイズの**有限性**

         ☞  確実なモデルを作成のためには無限のデータ数が必要

    - **決定理論**との組み合わせにより、不完全で曖昧な情報から最適な予測が可能
- 確率の大原則として、**確率の加法定理**(sum rule of probability)と**確率の乗法定理**(product rule of probability)が必要不可欠
    - 加法定理

        $$
        p(X=x_i)=\sum_{j=1}^Lp(X=x_i, Y=y_j)
        $$

    - 乗法定理

        $$
        p(X=x_i, Y=y_j) = p(X=x_i | Y=y_j)~p(Y=y_j)
        $$

- **ベイズの定理** (Bayes’ theorem) は条件付き確率の間の関係性のことである

    $$
    p(Y|X) = \frac{p(X|Y) ~ p(Y)}{P(X)}
    $$

- 果物(=F)と箱(=B)の例を考える
    - 🟥 赤い箱: 🍎りんご: 2個, 🍊オレンジ: 6個, 選ぶ確率4/10
    - 🟦 青い箱: 🍎りんご: 3個, 🍊オレンジ: 1個, 選ぶ確率6/10
        - **事前確率**(prior probability)
            - 選んだ果物の種類を教えられる前にどの箱を選んだか尋ねられたら、我々が持つ完全な情報は $p(B)$ という確率値で与えられる
                - 選ばれた果物が何かわからない状態:  $p(B=🟥)=4/10$
        - **事後確率**(posterior probability)
            - 選ばれた果物が判明すれば、ベイズの定理より$p(B|F)$を計算できる
                - 🍊オレンジが選ばれたと判明した状態:  $p(B=🟥) = 2/3$
                - これは、青い箱からはオレンジは選ばれにくいという直感と一致している
- 2つの変数の同時分布がその周辺分布の積に分解できることを $X$と$Y$は**独立**(independent)であるという

### 1.2.1: 確率密度

離散的な事象集合に定義される確率分布のように、**連続変数**に対しても同様に**確率**というものを考えたい

- 実数値を取る変数xが区間$(x, x+\delta x)$に入る確率が、$\delta \rightarrow0$の時、$p(x)\delta x$で与えられる時、$p(x)$のことを**確率密度関数**(probability density)と呼ぶ
    - 任意の値は正で、総和は１
- 変数に非線形な変換を施すと、確率密度は**ヤコビ行列**により単純な関数とは異なる方法で変換される
    - これにより確率密度の最大値は変数の選び方に依存するということがわかる
- xが区間$(-\infin, z)$に入る確率は特別に**累積分布関数**(cummulative distribution function)
- $\mathbf{x} = (x_1, ..., x_D)$ を満たすベクトルを考えると、同時分布 $p(\mathbf{x}) = p(x_1, ..., x_D)$ を定義することができ、$\mathbf{x}$  が $\mathbf{x}$ を含む無現象の体積要素 $\delta x$ に入る確率は$p(\mathbf{x})\delta \mathbf{x}$で与えられる
    - 任意の値は正で、総和は１
- $x$が離散の場合、 $p(x)$ は**確率質量関数**(probability mass function)と呼ばれることもある
    - xの取りうる値の範囲に「確率の質量」が集中していると見做せるため
    - 離散の場合、大半の$x$において$p(x)=0$
- 確率の加法・乗法定理およびベイズの定理は連続変数の時もかのように定義される
    - 厳密には**測度論**(measure theory)が必要になる

### 1.2.2: 期待値と分散

**確率**を含む最も重要な操作の内１つは**関数**の**重み付き平均**を計算すること

- ある関数$f(x)$の確率分布$p(x)$のもとで平均値を$f(x)$の**期待値**(expectation)と呼ぶ

    $$
    \mathbb{E}[f] = \sum_xp(x)f(x)
    $$

    - 上記の式は離散分布に対した期待値
    - 表記上、$\mathbb{E}[f]$に$p(x)$が記載されない点に注意
- 確率分布や確率密度から得られた有限個の$N$点を用いて、期待値を近似可能
- 多変数関数に対しても同様に期待値を考えることは可能
    - どの変数に対して平均を取るのかが大事なので、$\mathbb{E}_x[f]$のように添字を用いる
- $f(x)$の**分散**(variance)は以下のように定義される

    $$
    \text{var}[f] = \mathbb{E}\Bigl[(f(x) - \mathbb{E}[f(x)])^2\Bigr]
    $$

    - $f(x)$が平均値$\mathbb{E}[f(x)]$の周辺でどの程度バラついているかを表現する尺度
    - $f(x)$と$f(x)^2$の期待値を用いて記述することも可能
- ２つの確率変数$x, y$の**共分散**(covariance)は以下のように定義される

    $$
    \begin{aligned}
    \text{cov}[x, y] &= \mathbb{E}_{x, y}[\{x-\mathbb{E}[x]\}~\{y-\mathbb{E}[y]\}]\\
     &= \mathbb{E}_{x, y}[xy] - \mathbb{E}[x]\mathbb{E}[y]
    \end{aligned}
    $$

    - $x$と$y$が”同時に変動する度合い”を表現している
    - $x$と$y$が独立なら$0$になる

### 1.2.3: ベイズ確率

ベイズ的考え方を用いることで、不確実性を定量化したい

- **頻度主義的**(frequentist)**確率**

  - 同じ条件下で無限に試行を繰り返した場合の結果の頻度
  - 固定された真の確率を持つと見なす
  - 「明日雨が降る確率は0.3だ」という表現に対して、「１度切りの明日という事象に関して、雨が降るという出来事に対して0.3分の信念を所持している」という考え方になる

- **ベイズ的**(Bayesian)**確率**

  - 未知の事象やパラメータに対する主観的な信念を表現するための手段
  - 新しい情報によってその信念が更新される
  - 「明日雨が降る確率は0.3だ」という表現に対して、「今日という日に対して無限回事象を繰り返すと明日雨の割合は0.3に収束する」という考え方になる
- ベイズ的確率の考え方の例
    - 月がかつて太陽を廻る軌道上にあったかどうか
    - 南極の万年雪が今世紀末には消えるのかどうか

     ☞  沢山の繰り返し観測ができる事象ではない

- 上記の状況に対しては以下のような流れを考える
    1. 不確実性を定量的に表現
        - $p(\bm{w})$の決定
    2. 新たな証拠に照らしてそれを正しく修正
        - $p(\bm{w}|\mathcal{D})$を計算
    3. その結果として最適な行動や決定を下す

     ☞  この一連の流れは一般的なベイズ的な確率の解釈によって実現が可能

- ベイズの定理(再掲)
    - 観測されたデータで与えられた証拠を取り組むことで、事前分布を事後分布に変換

        $$
        p(\bm{w}|\mathcal{D}) = \frac{p(\mathcal{D}|\bm{w})~p(\bm{w})}{p(\mathcal{D})}
        $$

        - $p(\bm{w}):$  パラメータ$\bm{w}$に関する**事前分布**
            - コイン投げの場合、$p(w_{表}, w_{裏}) = (1/2, 1/2)$ の確率が一番高いはずという情報
                - これにより、3回中3回”表”が出たとしても $p(X={表}) = 1$ とはならない
        - $p(\mathcal{D}|\bm{w}):$  パラメータ$\mathbf{w}$が定まったと仮定した時の観測データ $\mathcal{D}$ の確率
            - 上記でも説明した**尤度関数**に対応している
            - 頻度主義的な設定の場合、只々これを最大化することが目的となる
        - $p(\bm{w}|\mathcal{D}):$  観測データが一意に定まった時のパラメータ$\bm{w}$の確率
            - 果物と箱の例を考えたらわかるように、一見、パラメータ$\mathbf{w}$があり、そこから観測データ$\mathcal{D}$が生成されているのが普通の考え
            - しかし、$\mathcal{D}$が定まる($\mathcal{D}$を観測する)ことでどのような$\mathbf{w}$であったかの情報を得ることが可能である
            - 要するに、$p(\bm{w}|\mathcal{D})$は事前分布$p(\bm{w})$に対して観測データ情報$p(\mathcal{D}|\bm{w})$を加えた結果、修正された確率分布(すなわち**事後分布**)を示している
        - $p(\mathcal{D}):$  観測データに関する確率
            - 特定のパラメータ$\mathbf{w}$に対応したもの**ではない**観測データ$\mathcal{D}$の確率
            - 観測データの大きさを調整する正規化の役割を果たしている
    - 総括すると
        1. 事前/事後分布はパラメータの確率分布
            - 多項式フィッティングの例だと係数$\bm{w}$に対応している
            - 事後分布は事前分布に観測データの情報を付与したもの
                - 🧐 今までの観測データだと$p(\bm{w})$だと思っていたけど、新しい観測結果は$\mathcal{D}$だったからちょっと$p(\bm{w}|\mathcal{D})$に調整するか、というイメージ
        2. 尤度関数はデータの確率分布
            - 多項式フィッティングの例だと$x^j$に対応している
            - また計算するときは基本的に観測”後”、すなわち、確率が定まった後の話になるので、逆説的に$\mathbf{w}$の最適化に繋がる
                - 🧐 ベイズ主義者の気持ちとしては、**未知**のパラメータ$\bm{w}$から**既知/確実**な観測データ$\mathcal{D}$を推定したいという気持ちでいる
                    - 🧐 大前提にパラメータ$\bm{w}$が定まっていて、だからこそ$\mathcal{D}$は観測されるという掟みたいなものがある→わかりみ
                    - 🧐 $\bm{w}$はどんなものかわからないけど、観測結果はこれだった→じゃあ$\bm{w}$はこれだったと考えると一番都合いいね、というイメージ？
                - 🧐 観測データ$\mathcal{D}$は**確実**であることがポイント
                - 🧐 ベイズを理解するためには頻度主義者が扱う尤度関数とベイズ主義者が扱う尤度関数の違いを明確にすることが大事？
- 頻度主義的確率
    - 広く用いられている推定量は**最尤推定**(maximum likelihood)
        - 尤度関数 $p(\mathcal{D}|\mathbf{w})$ を最大にする$\mathbf{w}$を求める
            - 尤度関数の対数の符号を反転したものは**誤差関数**(error function)と呼ばれる
    - 頻度主義者は$\bm{w}$を「推定量」として捉えている
        - 無限の観測データがあれば誤差がないパラメータを推定できる
        - 🧐 観測データ$\mathcal{D}$からパラメータ$\bm{w}$を推定したいという気持ちでいる
            - 🧐 観測結果から法則性を見出す、というイメージ？
        - 🧐 言わば”普通”の確率の考え方な気がする
    - 頻度主義で誤差範囲をを決めるアプローチの一つとして、**ブートストラップ**(bootstrap)というものがある
        - **モンテカルロ法**の一種
        - 非常に柔軟な手法で、様々なモデルに適用が可能である
- 🧐 頻度主義者とベイズ主義者の最も大きな違いは、**矢印の向き**($\mathcal{D}\rightarrow\bm{w}$ or $\bm{w}\rightarrow\mathcal{D}$)

### 1.2.4: ガウス分布

様々な確率分布の中で最も重要な**正規分布**(normal distribution)または**ガウス分布**(Gaussian distribution)という分布を導入する

$$
\mathcal{N}(x~|~\mu, \sigma^2) = \frac{1}{\sqrt{2\pi \sigma^2}}\exp\Bigl\{-\frac{1}{2\sigma^2}(x-\mu)^2\Bigr\}
$$

- $\mu:$  **平均**(mean)
- $\sigma^2:$  **分散**(variance) ($\sigma:$  **標準偏差**(standard deviation))
    - $\beta~(=1/\sigma^2):$  **精度パラメータ**(precision parameter)
- $\mathcal{D}$次元ベクトルの連続変数$\bm{x}$について、多変量ガウス分布は以下の通りに定義される

    $$
    \mathcal{N}(\bm{x}~|~\boldsymbol\mu, \mathbf{\Sigma}) = \frac{1}{(2\pi)^{D/2}}\frac{1}{|\Sigma|^{1/2}}\exp\biggl\{-\frac{1}{2}(\bm{x}-\boldsymbol\mu)^\top\Sigma^{-1}(\bm{x}-\boldsymbol\mu)\biggr\}
    $$

    - $\boldsymbol\mu:$  平均のD次元ベクトル
    - $\Sigma:$  共分散行列
- 以下では、$N$個の単一の観測値からなるデータ集合を$\mathbf{x}$とする
    - $\bm{x} = (x_1, ..., x_D):$ １つの D次元観測データ
    - $\mathbf{x} = (x_1, ..., x_N):$  $N$個の単一観測データ
- 観測データ点が同一分布から独立に生成されるとき、**独立同分布**(independent identically distributed)であるといい、i.i.dと省略することが多い
    - 独立同分布の場合、一つ一つの単一観測データの確率を計算して、積を取れば良い

        $$
        p(\mathbf{x}~|~\mu, \sigma^2) = \prod_{n=1}^N \mathcal{N}(x_n~|~\mu, \sigma^2)
        $$

    - 上記の式を$\mu, \sigma^2$の関数と見ることで尤度関数と見ることも可能
        - 計算時はよく対数を取って考える
        - 計算結果はそれぞれ**サンプル平均**(sample mean)$\mu_{ML}$及び**サンプル分散(**sample variance)$\sigma^2_{ML}$となる
        - これらの期待値を考えると以下の通り

        - 平均

            $$
            \mathbb{E}[\mu_{ML}] = \mu
            $$


        - 分散

            $$
            \mathbb{E}[\sigma^2_{ML}] = \frac{N-1}{N}\sigma^2
            $$

        - 平均は問題なく計算されている(すなわち不偏推定量である)ことに対して、分散が過小評価されている

### 1.2.5: 曲線フィッティング再訪

多項式曲線フィッティング i) 誤差関数及び正則化に関する洞察を得る, ii)完全なベイズ的取り扱いを知るという目的を達成するために確率的な観点から眺め直す

- 曲線フィッティングの問題の目標
 ☞  $N$個の入力値とそれに対応する目標値にて構成されている訓練データに基づいて、新しい入力値に対する目標変数の予測ができるようにすること
- 目標値 $t$ はガウス分布に従うものとする

    $$
    p(t~|~x, \bm{w}, \beta) = \mathcal{N}(t~|~y(x, \bm{w}), \beta^{-1})
    $$

    - 🧐 尤度関数のようなものなはず
    - 🧐 $t_n$ を多項式でフィッティングしたいだけであって $t_n = y(x_n, \bm{w})$ではないことに注意
    - 🧐 １観測点に１つのガウス分布を割り当てている
1. 予測を行うためには初めに、分布のパラメータ$\mu, \sigma^2$を計算する必要がある
    - 以下では訓練データ$\{\mathbf{x}, \mathbf{t}\}$に基づいた最尤推定でパラメータ$\bm{w}, \beta$を求める
    - 上記のガウス分布を基に、$N$個の観測データから尤度関数を算出し、解くと
        - $\bm{w}_{ML}:$   二乗和誤差の最小化
        - $\beta_{ML}:$  観測結果と予測の分散
    - パラメータ$\bm{w}, \beta$が求まったので、**予測分布**(predictive distribution)という形で $t$ の確率分布を与えることができる

    $$
    p(t~|~x, \bm{w}_{ML}, \beta_{ML}) = \mathcal{N}(t~|~y(x, \bm{w}_{ML}), \beta_{ML}^{-1})
    $$

    - ここに、目標値 $t$ が未知な$x$を与えてあげることで $t$ に関する情報が手に入る
    - 🧐 確実な観測データを用いて、不確実なパラメータ$\bm{w}, \beta$を事前分布無しで確実化した
        - 確実化→最大値を計算
2. ベイズ的なアプローチのために、多項式の係数$\bm{w}$に関する事前分布を導入する

    $$
    p(\bm{w}~|~\alpha) = \mathcal{N}(\bm{w}~|~\mathbf{0}, \alpha^{-1}\text{I}) = \Bigl(\frac{\alpha}{2\pi}\Bigr)^{(M+1)/2}\exp\Bigl\{-\frac{\alpha}{2}\bm{w}^\top\bm{w}\Bigr\}
    $$

    - $\alpha:$  分布を制御するパラメータ→**超パラメータ**(hyperparameter)
    - ベイズの定理より以下のような式が成立する

        $$
        p(\bm{w}~|~\mathbf{x}, \mathbf{t}, \alpha, \beta) \propto p(\mathbf{t}~|~\mathbf{x}, \bm{w}, \beta)~p(\bm{w}~|~\alpha)
        $$

        - このように得られた事後分布を最大化する事で尤もらしい$\bm{w}$を計算可能
        - このテクニックを**最大事後確率推定**(maximum posterior)あるいは単に**MAP推定**と呼ぶ
        - 尤度関数 $p(\mathbf{t}~|~\mathbf{x}, \bm{w}, \beta)$ を最大化する $t$ を答えとするのは１の考え方
    - 事後分布の最大値は、正則化された二乗和誤差の最小化と同価値

        $$
        \frac{\beta}{2}\sum_{n=1}^N\{y(x_n, \mathbf{w}) - t_n\}^2+\frac{\alpha}{2}\mathbf{w}^\top\mathbf{w}
        $$

    - しかし、これも事前分布に対する事後分布を考え、それに関する点推定を行っているだけで、完全なベイズアプローチではない
    - 🧐 確実な観測データを用いて、不確実なパラメータ$\bm{w}$を事前分布を用いて確実化した

### 1.2.6: ベイズ曲線フィッティング

完全なベイズアプローチを考える
- ベイズ的な扱いというのは、確率の加法・乗法定理を矛盾なく適用することに他ならない
    - 以下では、$\alpha,~\beta$は事前にわかっている固定されたパラメータであると考える

    $$
    p(t~|~x, \mathbf{x}, \mathbf{t}) = \int p(t~|~x, \bm{w})~p(\bm{w}~|~\mathbf{x}, \mathbf{t})~\text{d}\bm{w}
    $$

    - $p(t~|~x, \bm{w}):$  入力及びパラメータに基づいて算出される目標値の分布
    - $p(\bm{w}~|~\mathbf{x}, \mathbf{t}):$  訓練データに基づいて算出されるパラメータの分布、すなわち事後分布
        - 今回は上記の２つどちらともガウス分布
    - 🧐 1.2.5節では、上記の式に関して$p(\bm{w}~|~\mathbf{x}, \mathbf{t})$から特定の$\bm{w}$を計算し、$p(t~|~x, \bm{w})$に適用することで予測分布を計算していた
    - 🧐 完全なベイズアプローチは、最大化する$\bm{w}$を点推定するのではなく、確率に応じて重み付き平均を計算するようなもの
- 上記の積分を計算すると以下のような結果が得られる

    $$
    p(t~|~x, \mathbf{x}, \mathbf{t}) = \mathcal{N}(t~|~m(x), s^2(x))
    $$

    平均と分散は以下の通り

    $$
    \begin{align*}
    m(x) &= \beta\phi(x)^\top \boldsymbol S\sum_{n=1}^N\phi(x_n)t_n \\
    s^2(x) &= \beta^{-1}+\phi(x)^\top \boldsymbol S\phi(x)
    \end{align*}
    $$

    - 上記の分散及び平均は $x$ に依存している
    - $s^2(x)$の第１項は目標変数のノイズによる不確実性($\beta_{ML}$に相当)、第２項は$\bm{w}$に対する不確実性

    行列 $\mathbf{S}$ は以下の通り

    $$
    \mathbf{S}^{-1} = \alpha \text{I} + \beta\sum_{n=1}^N\phi(x_n)\phi(x_n)^\top
    $$

    - $\text{I}:$  単位行列
    - $\phi_i(x):x^i~~(x = 0, ..., M)$

## 1.3: モデル選択

モデルの複雑さを支配するパラメータを実際に応用する際には決定する必要がある

- 最尤推定は過学習の問題があるので、良い指標とは言えない
- 様々なパラメータに対して、**確認用集合**(検証用集合; validation set)を用意する
    - しかしながら、訓練及びテストに用いることができるデータ数は限られているため、訓練データはたくさん確保したい
    - 一方、確認用集合が少なすぎると予測性能の推定の誤差が大きくなる
- 上記の問題点のため、**交差確認**(交差検証; cross-validation)を活用する
    - $(S-1)/S$の割合部分を訓練に用いつつ、全データを性能の評価に使うことができる
    - データが少ない場合は、$S=N$と考えるのが妥当であり、これを**LOO法**(１個抜き法; leave-one-out method)と呼ぶ
    - 大きなデメリットの一つとして、訓練の回数が$S$に比例して大きくなってしまう
- 訓練データだけに依存し、１回きりの訓練だけで複数のハイパーパラメータとモデルのタイプを比較できるものが望ましい

## 1.4: 次元の呪い

高次元空間の取り扱いは非常に難しい課題であり、パターン認識テクニックの設計に重要な影響を与える要因である

- 直感的には、近くの点が比較的大きな影響を与え、遠くの点には対して依存しないだろうと考える
    - 最も直感的なアプローチとしては、空間を分割し、同じ空間に属した訓練データのみで推定を行う
    - しかし、入力空間が高次元に拡張した場合に深刻なものとなる
        - データが存在しない部分空間が存在しないように多くの訓練データを必要とする
- 高次元を扱う際に伴う困難のことを**次元の呪い**(curse of dimensionality)と呼ぶ
    - 低次元における議論が高次元に一般化できるとは限らないことに注意する必要がある
    - 有効な対処法はないわけではない
        - 実データは多くの場合、実質的には低い次元の領域に入っている
            - すなわち、目標変数の重要な変化が生じる方向は限定されていることが多い
        - 大体のデータが一般的に滑らかな性質を持っている、すなわち、小さな変化は目標変数に関しても同様に小さい変化しか与えないことが多い
            - 局所的な内挿のような手法で入力変数の新たな値に対する予測をすることができる

## 1.5: 決定理論

パターン認識で遭遇する不確かさを含む状況における最適な意思決定を行う事を可能にする

- $p(x, t)$を訓練データ集合から決めることは**推論**(inference)
    - 但し、大半のケースは取り得る$t$に応じて特定の行動をとることが多い
    - 推論後には実際の行動を**決定**(decision)するフェースが必要ということ

### 1.5.1: 誤識別率の最小化

誤識別をできるだけ少なくしたいということだけを目標とする

- 決定のために規則が必要
    - 入力空間を各クラスの１つずつに対応する**決定領域**(decision region) $\mathcal{R}_k$ に分割する
        - 各決定領域上の点には全てクラス$\mathcal{C}_k$が割り当てられている
        - 連続とは限らない
    - 決定領域間の境界は**決定境界**(クラス境界; decision boundary)あるいは**決定表面**(decision surface)と呼ばれる
- 最も確率$p(x, \mathcal{C}_k)$が高い領域に分類させるべき

### 1.5.2: 期待損失の最小化

しかし、多くの応用では目的が単に誤識別を減らすよりも複雑化する

- **損失関数**(loss function)または**コスト関数**(cost function)を導入することで定式化が可能
    - 代わりに**効用関数**(ユーテリティ関数; utility function)を考えることもあり、この時は最大化が目標になる
- $x$の真のクラスが$\mathcal{C}_k$、予測で選ばれた$x$のクラスが$\mathcal{C}_j$の時、$L_{kj}$という**損失行列**(loss matrix)を考えることができる
    - 間違え先に対応した損失の大きさを丁寧に定義することが可能

### 1.5.3: 棄却オプション

クラス分類が難しい場合は、決定を避けることが適当な場合がある

- 🧐 全ての決定をAIに委ねる必要はないのではないか？という考え
    - 🧐 専門家が見るべき対象を減らすことも立派な貢献点
- この事を**棄却オプション**(reject option)と呼ぶ
    - すなわち、事後確率$p(\mathcal{C}_k~|~x)$の最大値が閾値 $\theta$ を下回る場合棄却するといった感じ
    - $K$クラス分類に対して、$\theta < 1/K$の場合、全ての選択が棄却されない

### 1.5.4: 推論と決定

決定問題を解く時、推論段階、決定段階、識別段階の３つのアプローチが考えられる

1. 訓練データからモデル$p(\mathcal{C}_k~|~x)$を学習する**推論段階**(inference stage)
2. 事後確率を用いて最適なクラスに割り当てを行う**決定段階**(decision stage)
3. 1, 2を同時に解いて入力$x$から直接決定関数を単に学習する**識別関数**(discriminant function)

複雑なものから順に上記のアプローチを並べる

1. クラスの条件付き密度$p(x~|~\mathcal{C}_k)$をクラス毎に決める推論問題を解く
    - 🧐 ここでは具体的な条件付き密度の計算方法は載っていない？枠組みだけ？
    - 事前クラス関数$p(\mathcal{C}_k)$を求め、ベイズの定理を使い事後確率$p(\mathcal{C}_k~|~x)$を計算する
        - 事前クラス関数は訓練集合の比率で簡単に推定することができる
    - 事後確率が分かれば決定理論により、新たな入力のクラス属性を決めることも可能
    - 出力の分布だけでなく、入力の分布 $p(x)$ もモデル化するアプローチはモデルからのサンプリングによって入力空間で人工データを生成できるため、**生成モデル**(generative model)と呼ばれる
        - 入力の分布は以下の通り

            $$
            p(x) = \sum_{k}p(x~|~\mathcal{C}_k) ~p(\mathcal{C}_k)
            $$

2. 事後確率を推論問題を解くことで解決し、その後決定理論を用いてそれぞれの新たな入力に対してクラスを１つに割り当てる
    - 🧐 1. との対応関係を敢えて出すなら、条件付き密度関数 $p(x~|~\mathcal{C}_k)$などを計算せず、直接、事後分布$p(\mathcal{C}_k~|~x)$を計算する方法
        - 🧐 こちらも枠組みだけ？
    - このような事後確率を直接モデル化するアプローチを**識別モデル**(判別モデル; discriminative model)という
3. 識別関数と呼ばれる、各入力データから直接クラスラベルに写像する関数を見つける
- 🧐 2. との対応関係を敢えて出すなら、事後分布$p(\mathcal{C}_k~|~x)$を計算せず、直接分類だけ行う方法

それぞれのアプローチに関するメリット・デメリットは以下の通り

1. データの周辺分布$p(x)$を求めることもできるが、使用しない場合計算資源の無駄
    - **外れ値検出**(outlier detection)または**新規性検出**(novelty detection)に役立つ
    - $p(x_{new})$が限りなく0に近いなら、$x_{new}$は良い観測データ/予測ではないと判断できる
2. 事後確率を$p(\mathcal{C}_k~|~x)$を直接計算できる
    - 機械学習の分野では、生成モデルか識別モデルかどちらのアプローチの方が優れているかという問題を探すことに関心がある
3. 推論と決定の段階は単一の学習問題に統合されている
   - しかし、事後計算を計算するメリットは数多くある
       1. リスク最小化
           - 損失行列が時間とともに変化する場合
       2. 棄却オプション
       3. クラス事前確率の補正
       4. モデルの結合
           - 異種の情報を処理するシステムを作成し、統合することが可能になる

### 1.5.5: 回帰のための損失関数

回帰問題における決定段階は、各入力$x$に対して、$t$の値に対する特定の推定値$y(x)$を選ぶこと

- 損失は$L(t, y(x))$として与えられる
    - よく用いられている損失関数は二乗誤差$L(t, y(x)) = \{y(x) - t\}^2$
    - 期待損失$\mathbb{E}[L]$は、ある事象が起きる確率と起きた時の損失の積を全ての観測値$x$及び目標値$t$で積分する
- 完全に自由な$y(x)$を選んで良いとするならば、**変分法**を用いて形式的に計算が可能
    - 計算結果は以下の通り

        $$
        y(\bm{x}) = \frac{\displaystyle\int t~p(\bm{x}, t)~dt}{p(\bm{x})} = \int t~p(\bm{x}~|~t)~dt = \mathbb{E}_t[t~|~\bm{x}]
        $$

        - $\mathbb{E}_t[t~|~\bm{x}]:$  $\bm{x}$ が与えられた時の $t$ の条件付き平均、**回帰関数**(regression function)として知られている
        - すなわち、最適解が $y(\bm{x}) = \mathbb{E}_t[t~|~\bm{x}]$ となる
- 回帰問題でもクラス分類問題と同様に、様々なアプローチが考えれる
    1. 同時分布$p(\bm{x}, t)$を推定する問題を解く、それから条件付き密度$p(t~|~\bm{x})$を求めるための規格化を行い、最後に条件付き平均$\mathbb{E}_t[t~|~\mathbf{x}]$を求める
    2. まず条件付き密度$p(t~|~\bm{x})$を推定する問題を解いてから、条件付き平均を求める
    3. 回帰関数を直接訓練データから計算する
- 損失関数は二乗損失が唯一の選択肢ではない
    - **ミンコフスキー損失**(Minkowski loss)というものがある
        - 二乗誤差の指数が超パラメータになっているもの

## 1.6: 情報理論

情報理論の分野から、パターン認識や機械学習テクニックの発展にも有用なことがわかっている幾つかの概念を導入する

- **情報量**: $h(x) = -\log_2p(x)$
- **エントロピー**: $\text{H}[x] = -\sum_xp(x)\log_2p(x)$
- **ノイズなし符号化定理**(noiseless coding theorem)
    - エントロピーは確率変数の状態を送るために必要なビット数の下界である
- エントロピーの別の見方をする
    - $N$個の同じ物体がたくさんの箱に分けられているという状況を考える

        $$
        W = \frac{N!}{\prod_i n_i!}
        $$

        - これを**多重度**(multiplicity)と呼ぶ
        - エントロピーは多重度の対数を適当に定数倍したものと定義される
        - 🧐 なぜ上のようになるかあまりわかっていない…
    - 箱の中の物体の特定の状態: **ミクロ状態**(微視的状態; microstate)
    - 比 $n_i/N$ で表される物体の占有数の分布は**マクロ状態**(微視的状態; macrostate)
    - 多重度はマクロ状態の**重み**(weight)とも呼ばれる
- エントロピーを連続変数$x$に拡張する
    - 具体的には**平均値の定理**(mean value theorem)などを活用する

        $$
        -\int p(x)\ln p(x)~dx
        $$

        - これは**微分エントロピー**(differential entropy)とも呼ばれる
- 微分エントロピーを最大化する分布はラグランジュ乗数法を活用することで、計算することができる
    - 結果としては、$p(x)$がガウス分布の時最大値を取る
        - 離散値の場合は全て同じ値の時であるが、連続値の場合はそうではない
            - 🧐 そもそも全て同じ確率となるケースがないことに注意
        - ガウス分布の微分エントロピーは計算すると

            $$
            \text{H}[x] = \frac{1}{2}\{1+\ln(2\pi\sigma^2)\}
            $$

            で与えられることがわかる

            - $\sigma^2 < 1/(2\pi e)$の時、微分エントロピーは負の値になるのも離散値の場合と大きく異なる
- **条件付きエントロピー**(conditional entropy)は以下の通り

    $$
    \text{H}[\bm{y}~|~\bm{x}] = -\int \int p(\bm{y},\bm{x}) \in p(\bm{y}~|~\bm{x})~d\bm{y} d\bm{x}
    $$

    - 確率の乗法定理を用いることで

        $$
        \text{H}[\bm{x}, \bm{y}] = \text{H}[\bm{y}~|~\bm{x}]+\text{H}[\bm{x}]
        $$

        が満たすことがわかる


### 1.6.1: 相対エントロピーと相互情報量

ある未知の分布$p(\bm{x})$を近似的に$q(\bm{x})$でモデルする事を考える

- $\bm{x}$の分布を特定する為に必要な**追加**(additional)情報の平均は

    $$
    \begin{align*}
    \text{KL}(p~||~q) &= -\int p(\bm{x})\ln q(\bm{x})~d\bm{x}-\Bigl(-\int p(\bm{x})\ln p(\bm{x})~d\bm{x}\Bigr)\\
    &=-\int p(\bm{x})\ln \Bigl\{\frac{q(\bm{x})}{p(\mathbf{x})}\Bigr\}~d\bm{x}
    \end{align*}
    $$

    - 分布間の**相対エントロピー**(relative entoropy)あるいは**カルバック-ライブラ-ダイバージェンス**(Kullback-Leibler divergence)として知られている
    - $\text{KL}(p~||~q) \not\equiv \text{KL}(q~||~p)$ であることに注意
- 未知の分布$p(\bm{x})$をモデル化する
    - 分布を知らないのでKLダイバージェンスに直接適用することは不可能であるが、有限個の訓練データ集合により近似することは可能である
        - この時、最尤推定による尤度の最大化と等価な式が得られる
- ２つの変数集合のときはがどれだけ独立に近いかを知るために$p(\mathbf{x}, \mathbf{y})$と$p(\bm{x}~|~\bm{y})$にKDダイバージェンスを適用する

    $$
    \begin{align*}
    \text{I}[\bm{x}, \bm{y}] &\equiv \text{KL}(p(\bm{x}, \bm{y})~||~p(\bm{x})~p(\bm{y}))\\
    &= -\int p(\bm{x}, \bm{y})~\ln \Bigl(\frac{p(\bm{x})p(\bm{y})}{p(\bm{x}, \bm{y})}\Bigr)d\bm{x}d\bm{y}
    \end{align*}
    $$

    - これは**相互情報量**(mutual information)という
    - 以下のような性質を満たす

        $$
        \text{I}[\bm{x}, \bm{y}] = \text{H}[\bm{x}] - \text{H}[\bm{x}~|~\bm{y}] = \text{H}[\bm{y}] - \text{H}[\bm{y}~|~\bm{x}]
        $$

        - すなわち、$\mathbf{y}$の値を知ることによって$\mathbf{x}$に関する不確実性がどれだけ減少するかを表している
        - ベイズ的な観点からは、$\bm{x}$を事前分布、$p(\bm{x}~|~\bm{y})$は新たなデータ$\bm{y}$の観測後の事後分布として考えることができる
